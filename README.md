ğŸš€ Projeto: IntegraÃ§Ã£o SQL com LangChain e OpenAI
ğŸ“š DescriÃ§Ã£o
Este projeto demonstra como integrar o LangChain com um banco de dados MySQL para converter perguntas em consultas SQL, executar essas consultas e retornar respostas em linguagem natural utilizando o ChatOpenAI. A estrutura modular permite expandir ou adaptar o pipeline conforme a necessidade.

ğŸ› ï¸ Funcionalidades
Carregamento seguro de variÃ¡veis de ambiente (API keys, senhas, etc.)
GeraÃ§Ã£o dinÃ¢mica de consultas SQL a partir de perguntas em linguagem natural
ExecuÃ§Ã£o de queries no banco de dados MySQL
GeraÃ§Ã£o de respostas finais em linguagem natural

ğŸ” Estrutura do CÃ³digo

import os
from dotenv import load_dotenv, find_dotenv
# Importa classes do LangChain (versÃµes customizadas/forks)
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.utilities import SQLDatabase
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI

# ğŸš€ Carregar variÃ¡veis de ambiente
# Carrega o arquivo .env para obter as chaves de API e senhas sem expÃ´-las no cÃ³digo
load_dotenv(find_dotenv())
OPENAI_KEY = os.environ['OPENAI_API_KEY']   # Chave da API da OpenAI
DB_PASSWORD = os.environ['DB_PASSWORD']       # Senha do MySQL

# (Opcional) ImportaÃ§Ã£o do prompt do prompt_toolkit - evite conflito de nomes se nÃ£o for utilizado
from prompt_toolkit import prompt

# ğŸ’¬ DefiniÃ§Ã£o do template para gerar a consulta SQL
# O template recebe o esquema da tabela e a pergunta do usuÃ¡rio para formular a consulta SQL
template = """
Based on the table schema below, write a SQL query that would answer the user's question:
{schema}

Question: {question}
SQL Query
"""
# Cria o objeto de prompt a partir do template
prompt = ChatPromptTemplate.from_template(template)
# Exemplo de formataÃ§Ã£o do template (apenas para teste)
prompt.format(schema='my schema', question="how many users are there!")

# ğŸ”— ConfiguraÃ§Ã£o da conexÃ£o com o MySQL
# Monta a URI de conexÃ£o utilizando o usuÃ¡rio root e a senha carregada do .env
db_uri = f"mysql+mysqlconnector://root:{DB_PASSWORD}@localhost:3306/chinook"
# Inicializa a conexÃ£o com o banco utilizando a classe SQLDatabase
db = SQLDatabase.from_uri(db_uri)

# ğŸ” FunÃ§Ã£o para obter o esquema das tabelas do banco de dados
def get_schema(_):
    return db.get_table_info()

# ğŸ¤– InicializaÃ§Ã£o do modelo de linguagem da OpenAI
llm = ChatOpenAI()

# ğŸ› ï¸ CriaÃ§Ã£o do pipeline SQL para gerar a consulta
sql_chain = (
    # Passa o esquema do banco para o pipeline
    RunnablePassthrough.assign(schema=get_schema)
    # Aplica o template para gerar a consulta SQL
    | prompt
    # Utiliza o modelo de linguagem para completar a consulta (parando antes de retornar o resultado)
    | llm.bind(stop="\nSQL Result:")
    # Converte a saÃ­da para uma string
    | StrOutputParser()
)
# Exemplo de invocaÃ§Ã£o do pipeline para gerar uma consulta com uma pergunta especÃ­fica
sql_chain.invoke({"question": "how many artists are there?"})

# ğŸ’¡ DefiniÃ§Ã£o de um template para gerar a resposta final em linguagem natural
# Esse template usa o esquema, a pergunta, a query gerada e a resposta SQL para formular uma resposta natural
template = """Based on the table schema below, question, sql query, and sql response, write a natural language response:
{schema}

Question: {question}
SQL Query: {query}
SQL Response: {response}"""
# Cria o objeto de prompt para a resposta final
prompt_response = ChatPromptTemplate.from_template(template)

# ğŸ”§ FunÃ§Ã£o que executa a query construÃ­da anteriormente no banco de dados
def run_query(query):
    return db.run(query)

# ğŸ”„ CriaÃ§Ã£o do pipeline completo que integra a consulta SQL e a resposta em linguagem natural
full_chain = (
    # Passa a consulta SQL gerada anteriormente para o pipeline
    RunnablePassthrough.assign(query=sql_chain).assign(
        # Re-obtem o esquema da base de dados
        schema=get_schema,
        # Executa a query e obtÃ©m a resposta do banco
        response=lambda variables: run_query(variables["query"]),
    )
    # Aplica o template para gerar a resposta final
    | prompt_response
    # Utiliza o modelo de linguagem para formatar a resposta
    | llm
)

# ğŸš€ ExecuÃ§Ã£o do pipeline completo com a pergunta final do usuÃ¡rio
full_chain.invoke({"question": "Quanto foi o faturamento total da empresa?"})
ğŸ“Œ ConsideraÃ§Ãµes Finais
SeguranÃ§a: VariÃ¡veis sensÃ­veis sÃ£o carregadas via .env, evitando exposiÃ§Ã£o direta no cÃ³digo.
Modularidade: O uso de pipelines facilita a manutenÃ§Ã£o e a expansÃ£o do projeto.
PersonalizaÃ§Ã£o: VocÃª pode alterar os templates e funÃ§Ãµes auxiliares para se adequar a diferentes tipos de queries ou bancos de dados.
ğŸ¯ Como Executar
Certifique-se de ter o arquivo .env com as seguintes variÃ¡veis:

OPENAI_API_KEY=your_openai_api_key_here
DB_PASSWORD=your_mysql_password_here
Instale as dependÃªncias necessÃ¡rias (por exemplo, pip install python-dotenv mysql-connector-python langchain ...).

Execute o script:

python seu_script.py

Agradecimento especial ao professor [@EduardoInocencio](https://github.com/EduardoVitorInocencio)